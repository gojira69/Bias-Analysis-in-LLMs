# Are NLP models biased?
The answer to this question is associated with the kind of `dataset` that the particular NLP model has been trained on. Most language models like`BERT` are trained on `wikipedia` and other similar text corpora. These sources have a large presence of the annotated stereotypical tuples mentioned in the research paper (section - 5.2) and which are found in the repository. 


So, we can say that the biasness of these LMs arises from the fact that these stereotypes are embedded in the datasets which are used to train them. 

# Are NLP models stereotypical towards a particular gender


