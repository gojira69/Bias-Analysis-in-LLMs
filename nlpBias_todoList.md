* Separate stereotypical tuples -----> `Done`

* Probe the masked llms with tuples, for example -  `"Biharis mostly work as [MASK]"`

* Do this for `region`, `religion` and `caste`.

* Try probing for gender analysis using names. For example - `"Gender of @ is [MASK]"`, where `@` is the name


# End Goal

Can you leverage this dataset to assess bias encoded into NLP models? Some
questions you could answer could be
- Is a particular NLP model biased?
- Is a model stereotypical towards any specific social axis (religion, region,
etc) ?
- Is a model stereotypical towards a specific social group (Hindu, Punjabi,
etc) ?
- How would you quantify bias through this method?

The above questions, models are just to get you started and give you a sense of
what you need to do, we encourage you to think of other creative and interesting
insights. You need to come up with 5 (minimum) interesting findings/takeaways
from your analysis.
